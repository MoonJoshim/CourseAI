#!/usr/bin/env python3
"""Pinecone ê°•ì˜ ë°ì´í„° API"""

from flask import Flask, jsonify, request
from flask_cors import CORS
import os
import json
import sys
from dotenv import load_dotenv
from pinecone import Pinecone
from collections import defaultdict
from sentence_transformers import SentenceTransformer
from langchain_pinecone import PineconeVectorStore
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
import google.generativeai as genai

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from backend.api import get_mongo_db

# LangChain Embeddings import (ë²„ì „ì— ë”°ë¼ ê²½ë¡œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
try:
    from langchain_core.embeddings import Embeddings
except ImportError:
    try:
        from langchain.embeddings.base import Embeddings
    except ImportError:
        from langchain.embeddings import Embeddings

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
CORS(app)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Pinecone ì—°ê²°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')
PINECONE_INDEX = os.getenv('PINECONE_INDEX', 'courses-dev')

pc = Pinecone(api_key=PINECONE_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Embedding ëª¨ë¸ - multilingual-e5-base
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# embedding_model = SentenceTransformer("intfloat/multilingual-e5-base")
embedding_model = SentenceTransformer("jhgan/ko-sroberta-multitask")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangChain Embeddings ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SentenceTransformerEmbeddings(Embeddings):
    """SentenceTransformerë¥¼ LangChain Embeddings ì¸í„°í˜ì´ìŠ¤ë¡œ ë˜í•‘"""
    
    def __init__(self, model: SentenceTransformer):
        self.model = model
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œ ì„ë² ë”© (passage í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©)"""
        # E5 ëª¨ë¸ì€ passage í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©
        formatted = [f"passage: {text}" for text in texts]
        embeddings = self.model.encode(formatted, normalize_embeddings=True)
        return embeddings.tolist()
    
    def embed_query(self, text: str) -> List[float]:
        """ì¿¼ë¦¬ ì„ë² ë”© (query í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©)"""
        # E5 ëª¨ë¸ì€ query í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©
        formatted = f"query: {text}"
        embedding = self.model.encode([formatted], normalize_embeddings=True)
        return embedding[0].tolist()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VectorStore ì´ˆê¸°í™” í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_vectorstore() -> PineconeVectorStore:
    """
    Pinecone VectorStore ì´ˆê¸°í™”
    upsertì™€ ë™ì¼í•œ êµ¬ì¡°ë¡œ ìƒì„±
    """
    embeddings = SentenceTransformerEmbeddings(embedding_model)
    vectorstore = PineconeVectorStore(
        index_name=PINECONE_INDEX,
        embedding=embeddings
    )
    return vectorstore

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangChain Pinecone VectorStore (ì „ì—­ ì¸ìŠ¤í„´ìŠ¤)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
vectorstore = init_vectorstore()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini LLM í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

genai.configure(api_key=GEMINI_API_KEY)

def call_gemini(prompt):
    model = genai.GenerativeModel("gemini-2.5-flash")
    response = model.generate_content(prompt)
    return response.text

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Intent í´ë˜ìŠ¤ (ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ê²°ê³¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class QueryIntent(BaseModel):
    """ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ê²°ê³¼"""
    needs_structured_filter: bool
    filters: Dict[str, Any]
    semantic_query: str

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper í•¨ìˆ˜ë“¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def classify_query_intent(user_query: str) -> QueryIntent:
    """
    ì§ˆë¬¸ ì˜ë„ ë¶„ì„ (Structured / Semantic ë¶„ë¦¬)
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  êµ¬ì¡°ì  í•„í„°ì™€ ì˜ë¯¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë¶„ë¦¬
    
    Args:
        user_query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        QueryIntent: ë¶„ì„ëœ ì˜ë„ ì •ë³´
    """
    try:
        # Gemini í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:

1. êµ¬ì¡°ì  í•„í„° í•„ìš” ì—¬ë¶€ (needs_structured_filter):
   - MongoDB courseì— ìˆëŠ” í•„ë“œë¡œ í•„í„°ë§ì´ í•„ìš”í•œì§€ íŒë‹¨
   - ì˜ˆ: "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜" â†’ true (department, course_type í•„í„° í•„ìš”)
   - ì˜ˆ: "ë°ì´í„°ë² ì´ìŠ¤ ë“¤ì„ê¹Œ ë§ê¹Œ?" â†’ true (course_name í•„í„° í•„ìš”)
   - ì˜ˆ: "ì´ë²ˆ í•™ê¸°ì— ì—´ë¦¬ëŠ” ì‰¬ìš´ ì „ê³µ ì„ íƒ(ì „ì„ ) ê³¼ëª© ì¤‘ì— ë¹„ëŒ€ë©´ ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ true (semester, lecture_type, course_type í•„í„° í•„ìš”)
   - ì˜ˆ: "ì†ê²½ì•„ êµìˆ˜ë‹˜ ì–´ë•Œ?" â†’ true (professor í•„í„° í•„ìš”)
   - ì˜ˆ: "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ false (êµ¬ì¡°ì  í•„í„° ë¶ˆí•„ìš”)
   - ì˜ˆ: "ë‚´ ê°œë°œ ì‹¤ë ¥ì— ì§„ì§œ ë„ì›€ë˜ëŠ” ê°•ì˜ ìˆì„ê¹Œ?" â†’ false (êµ¬ì¡°ì  í•„í„° ë¶ˆí•„ìš”)

2. MongoDB í•„í„° (filters):
   - êµ¬ì¡°ì  í•„í„°ê°€ í•„ìš”í•œ ê²½ìš°, ì¶”ì¶œ ê°€ëŠ¥í•œ í•„ë“œë“¤ì„ key-value í˜•íƒœë¡œ ì œê³µ
   - ê°€ëŠ¥í•œ í•„ë“œ: course_name, professor, department, semester, credits, lecture_time, lecture_method, course_type, subject_type
   - departmentëŠ” "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼"ë°–ì— ì˜¬ ìˆ˜ ì—†ê³ , course_typeëŠ” "ì „í•„", "ì „ì„ "ë°–ì— ì˜¬ ìˆ˜ ì—†ìŒ. lecture_timeëŠ” "ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ"ë°–ì— ì˜¬ ìˆ˜ ì—†ìŒ.
   - ì˜ˆ: {{"course_name": "ë°ì´í„°ë² ì´ìŠ¤"}}, {{"department": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼", "course_type": "ì „ì„ "}}
   - êµ¬ì¡°ì  í•„í„°ê°€ ë¶ˆí•„ìš”í•˜ë©´ ë¹ˆ ê°ì²´ {{}} ë°˜í™˜

3. ì˜ë¯¸ ê²€ìƒ‰ ì¿¼ë¦¬ (semantic_query):
   - êµ¬ì¡°ì  í•„í„° ë¶€ë¶„ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ìì—°ì–´ ì§ˆë¬¸ì„ ì •ì œ
   - êµ¬ì¡°ì  í•„í„°ê°€ í•„ìš”í•œ ê²½ìš°: í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„(ê³¼ëª©ëª…, êµìˆ˜ëª…, í•™ê³¼ëª…, í•™ê¸°, ìˆ˜ì—…ë°©ì‹ ë“±)ì„ ì œê±°í•˜ê³  ë‚˜ë¨¸ì§€ ì˜ë¯¸ ìˆëŠ” ì§ˆë¬¸ë§Œ ë‚¨ê¹€
   - êµ¬ì¡°ì  í•„í„°ê°€ ë¶ˆí•„ìš”í•œ ê²½ìš°: ì›ë³¸ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
   - ì¤‘ìš”: semantic_queryê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ê°€ ë¶ˆëª…í™•í•œ ê²½ìš°(ì˜ˆ: "ë“¤ì„ê¹Œ ë§ê¹Œ?"), ê°•ì˜í‰ì´ë‚˜ ê°•ì˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì˜ë¯¸ë¥¼ í™•ì¥í•˜ê±°ë‚˜, ì¥ë‹¨ì ì„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ê²€ìƒ‰ ë° ì •ë¦¬ ìˆ˜í–‰
   - ì˜ˆ: "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜" â†’ "ê³¼ëª© ì¶”ì²œí•´ì¤˜" (department, course_type ì œê±°)
   - ì˜ˆ: "SWìº¡ìŠ¤í†¤ë””ìì¸ ë“¤ì„ê¹Œ ë§ê¹Œ?" â†’ "ê°•ì˜ ì–´ë•Œ" ë˜ëŠ” "ê°•ì˜ ì¥ë‹¨ì  ì •ë¦¬í•´ì¤˜" (course_name ì œê±°, ì˜ë¯¸ í™•ì¥)
   - ì˜ˆ: "ì´ë²ˆ í•™ê¸°ì— ì—´ë¦¬ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ "ê°•ì˜ ì¶”ì²œí•´ì¤˜" (course_name, semester ì œê±°)
   - ì˜ˆ: "ì´ë²ˆ í•™ê¸°ì— ì—´ë¦¬ëŠ” ì‰¬ìš´ ì „ê³µ ì„ íƒ(ì „ì„ ) ê³¼ëª© ì¤‘ì— ë¹„ëŒ€ë©´ ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ "ì‰¬ìš´ ê°•ì˜ ì¶”ì²œí•´ì¤˜" (semester, lecture_type, course_type ì œê±°)
   - ì˜ˆ: "ì†ê²½ì•„ êµìˆ˜ë‹˜ ì–´ë•Œ?" â†’ "êµìˆ˜ë‹˜ ê°•ì˜ ì–´ë•Œ" (professor ì œê±°, ì˜ë¯¸ í™•ì¥)
   - ì˜ˆ: "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜" (êµ¬ì¡°ì  í•„í„° ì—†ìŒ, ì›ë³¸ ê·¸ëŒ€ë¡œ)
   - ì˜ˆ: "ë‚´ ê°œë°œ ì‹¤ë ¥ì— ì§„ì§œ ë„ì›€ë˜ëŠ” ê°•ì˜ ìˆì„ê¹Œ?" â†’ "ë‚´ ê°œë°œ ì‹¤ë ¥ì— ì§„ì§œ ë„ì›€ë˜ëŠ” ê°•ì˜ ìˆì„ê¹Œ?" (êµ¬ì¡°ì  í•„í„° ì—†ìŒ, ì›ë³¸ ê·¸ëŒ€ë¡œ)

ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ì¶”ê°€ ì„¤ëª… ì—†ì´):
{{
    "needs_structured_filter": true/false,
    "filters": {{}},
    "semantic_query": "ì •ì œëœ ì§ˆë¬¸"
}}"""

        # Gemini ëª¨ë¸ í˜¸ì¶œ
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()
        
        # JSON íŒŒì‹±
        intent_data = json.loads(response_text)
        
        # QueryIntent ê°ì²´ ìƒì„±
        return QueryIntent(
            needs_structured_filter=intent_data.get("needs_structured_filter", False),
            filters=intent_data.get("filters", {}),
            semantic_query=intent_data.get("semantic_query", user_query)
        )
        
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"   Gemini ì‘ë‹µ: {response_text if 'response_text' in locals() else 'N/A'}")
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return QueryIntent(
            needs_structured_filter=False,
            filters={},
            semantic_query=user_query
        )
    except Exception as e:
        print(f"âŒ ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return QueryIntent(
            needs_structured_filter=False,
            filters={},
            semantic_query=user_query
        )

def filter_from_mongodb(filters: Dict[str, Any]) -> Optional[List[Dict[str, Any]]]:
    """
    MongoDBì—ì„œ êµ¬ì¡°ì  í•„í„°ë¡œ ê°•ì˜ ê²€ìƒ‰
    
    Args:
        filters: í•„í„° ë”•ì…”ë„ˆë¦¬ (department, course_name, professor, 
                semester, credits, course_type, subject_type, lecture_time, lecture_method ë“±)
        
    Returns:
        List[Dict]: ê°•ì˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (course_name, professor, department ë“± í¬í•¨)
    """
    try:
        if not filters:
            return None
        
        db = get_mongo_db()
        collection = db.courses
        
        # ë™ì  ì¿¼ë¦¬ êµ¬ì„±
        query = {}
        
        # department í•„í„°
        if "department" in filters:
            query["department"] = {"$regex": filters["department"], "$options": "i"}
        
        # course_name í•„í„°
        if "course_name" in filters:
            query["course_name"] = {"$regex": filters["course_name"], "$options": "i"}
        
        # professor í•„í„°
        if "professor" in filters:
            query["professor"] = {"$regex": filters["professor"], "$options": "i"}
        
        # semester í•„í„° (yearì™€ ë³„ë„)
        if "semester" in filters:
            query["semester"] = filters["semester"]
        
        # credits í•„í„°
        if "credits" in filters:
            query["credits"] = filters["credits"]
        
        # course_type í•„í„° (ì „í•„, ì „ì„  ë“±)
        if "course_type" in filters:
            query["course_type"] = {"$regex": filters["course_type"], "$options": "i"}
        
        # subject_type í•„í„°
        if "subject_type" in filters:
            query["subject_type"] = {"$regex": filters["subject_type"], "$options": "i"}
        
        # lecture_time í•„í„°
        if "lecture_time" in filters:
            query["lecture_time"] = {"$regex": filters["lecture_time"], "$options": "i"}
        
        # lecture_method í•„í„° (ë¹„ëŒ€ë©´, ëŒ€ë©´ ë“±)
        if "lecture_method" in filters:
            query["lecture_method"] = {"$regex": filters["lecture_method"], "$options": "i"}
        
        if not query:
            return None
        
        # MongoDB ê²€ìƒ‰ ì‹¤í–‰
        cursor = collection.find(query).limit(100)  # ìµœëŒ€ 100ê°œ
        results = []
        
        for doc in cursor:
            course_data = {
                "course_name": doc.get("course_name", ""),
                "professor": doc.get("professor", ""),
                "department": doc.get("department", ""),
                "semester": doc.get("semester", ""),
                "credits": doc.get("credits", 3),
                "course_type": doc.get("course_type", ""),
                "subject_type": doc.get("subject_type", ""),
                "lecture_time": doc.get("lecture_time", ""),
                "lecture_method": doc.get("lecture_method", ""),
                "course_id": doc.get("course_id", ""),
                "rating": doc.get("rating", 0.0),
                "average_rating": doc.get("average_rating", 0.0),
                "total_reviews": doc.get("total_reviews", 0)
            }
            results.append(course_data)
        
        print(f"âœ… MongoDBì—ì„œ {len(results)}ê°œ ê°•ì˜ ë°œê²¬ (í•„í„°: {filters})")
        return results if results else None
        
    except Exception as e:
        print(f"âŒ MongoDB í•„í„°ë§ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

def semantic_search_pinecone(query: str, candidates: Optional[List[Dict[str, Any]]] = None, top_k: int = 5) -> List[Dict[str, Any]]:
    """
    Pinecone ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (metadata í•„í„° ì§€ì›)
    
    Args:
        query: ê²€ìƒ‰í•  ì¿¼ë¦¬ í…ìŠ¤íŠ¸
        candidates: MongoDB í›„ë³´ ëª©ë¡ (course_name ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ í•„í„°ë§ì— ì‚¬ìš©)
        top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
    Returns:
        List[Dict]: metadataì™€ textë¥¼ í¬í•¨í•œ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        [
            {
                "text": "ë¬¸ì„œ ë‚´ìš©",
                "metadata": {...}
            },
            ...
        ]
    """
    try:
        # Pinecone í•„í„° êµ¬ì„±
        pinecone_filter = {}
        
        if candidates:
            # candidatesì—ì„œ course_name ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            course_names = []
            for candidate in candidates:
                course_name = candidate.get("course_name", "")
                if course_name:
                    course_names.append(course_name)
            
            if course_names:
                # Pinecone metadata í•„í„°: course_nameì´ candidates ì¤‘ í•˜ë‚˜ì™€ ì¼ì¹˜
                pinecone_filter = {
                    "course_name": {"$in": course_names}
                }
                print(f"ğŸ” Pinecone í•„í„° ì ìš©: {len(course_names)}ê°œ course_name")
        
        # VectorStoreì—ì„œ retriever ìƒì„± (í•„í„° í¬í•¨)
        search_kwargs = {"k": top_k}
        if pinecone_filter:
            search_kwargs["filter"] = pinecone_filter
        
        retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)
        
        # ê²€ìƒ‰ ì‹¤í–‰ (embed_queryê°€ ìë™ìœ¼ë¡œ "query:" í”„ë¦¬í”½ìŠ¤ ì¶”ê°€)
        # Note: embed_query ë©”ì„œë“œê°€ ì´ë¯¸ "query: {text}" í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ
        # ì›ë³¸ queryë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ë©´ ë¨
        docs = retriever.get_relevant_documents(query)
        
        # ê²°ê³¼ë¥¼ Dict í˜•íƒœë¡œ ë³€í™˜
        results = []
        for doc in docs:
            results.append({
                "text": doc.page_content,
                "metadata": doc.metadata
            })
        
        print(f"âœ… Pineconeì—ì„œ {len(results)}ê°œ ê°•ì˜í‰ ë°œê²¬")
        return results
        
    except Exception as e:
        print(f"âŒ Pinecone ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return []

def merge_results(mongo_candidates: Optional[List[Dict[str, Any]]], pinecone_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ë‘ ê²°ê³¼ë¥¼ merge â†’ ê°•ì˜ ì •ë³´ + ë¦¬ë·° ì •ë³´ í†µí•©
    
    Args:
        mongo_candidates: MongoDBì—ì„œ ê²€ìƒ‰ëœ ê°•ì˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        pinecone_results: Pineconeì—ì„œ ê²€ìƒ‰ëœ ê°•ì˜í‰ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        Dict: ë³‘í•©ëœ ê°•ì˜ ì •ë³´ (course_nameë³„ë¡œ ê·¸ë£¹í™”, ë¦¬ë·° í¬í•¨)
    """
    # course_nameë³„ë¡œ ê°•ì˜í‰ ê·¸ë£¹í™”
    reviews_by_course = defaultdict(list)
    
    for review in pinecone_results:
        metadata = review.get("metadata", {})
        course_name = metadata.get("course_name", "")
        
        if course_name:
            review_data = {
                "text": review.get("text", ""),
                "review_id": metadata.get("original_id", ""),
                "sentiment": None  # í–¥í›„ ê°ì • ë¶„ì„ ì¶”ê°€ ê°€ëŠ¥
            }
            reviews_by_course[course_name].append(review_data)
    
    # MongoDB ê°•ì˜ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
    if mongo_candidates:
        courses = []
        mongo_course_map = {course.get("course_name", ""): course for course in mongo_candidates if course.get("course_name")}
        
        for course_name, reviews in reviews_by_course.items():
            mongo_course = mongo_course_map.get(course_name, {})
            
            course_entry = {
                "course_name": course_name,
                "professor": mongo_course.get("professor", ""),
                "department": mongo_course.get("department", ""),
                "rating": mongo_course.get("rating", 0.0) or mongo_course.get("average_rating", 0.0),
                "review_count": len(reviews),
                "reviews": reviews
            }
            courses.append(course_entry)
        
        # MongoDBì— ìˆì§€ë§Œ ë¦¬ë·°ê°€ ì—†ëŠ” ê°•ì˜ë„ ì¶”ê°€
        for course in mongo_candidates:
            course_name = course.get("course_name", "")
            if course_name and course_name not in reviews_by_course:
                course_entry = {
                    "course_name": course_name,
                    "professor": course.get("professor", ""),
                    "department": course.get("department", ""),
                    "rating": course.get("rating", 0.0) or course.get("average_rating", 0.0),
                    "review_count": 0,
                    "reviews": []
                }
                courses.append(course_entry)
    else:
        # MongoDB í›„ë³´ê°€ ì—†ëŠ” ê²½ìš° (semantic-only queries)
        # Pinecone metadataì—ì„œë§Œ ê°•ì˜ ì •ë³´ ì¶”ì¶œ
        courses = []
        course_info_map = {}
        
        for review in pinecone_results:
            metadata = review.get("metadata", {})
            course_name = metadata.get("course_name", "")
            
            if course_name and course_name not in course_info_map:
                course_info_map[course_name] = {
                    "professor": metadata.get("professor", ""),
                    "department": metadata.get("department", ""),
                    "rating": metadata.get("rating", 0.0)
                }
        
        for course_name, reviews in reviews_by_course.items():
            info = course_info_map.get(course_name, {})
            course_entry = {
                "course_name": course_name,
                "professor": info.get("professor", ""),
                "department": info.get("department", ""),
                "rating": float(info.get("rating", 0.0)) if info.get("rating") else 0.0,
                "review_count": len(reviews),
                "reviews": reviews
            }
            courses.append(course_entry)
    
    return {
        "courses": courses
    }

def normalize_context(merged_context: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë³‘í•©ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ì—¬ LLM í”„ë¡¬í”„íŠ¸ì— ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì²˜ë¦¬
    
    Args:
        merged_context: merge_results()ì˜ ì¶œë ¥
        
    Returns:
        Dict: ì •ê·œí™”ëœ ì»¨í…ìŠ¤íŠ¸ (ëª¨ë“  í•„ìˆ˜ í•„ë“œ ë³´ì¥, ë¦¬ë·° í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ)
    """
    normalized = {
        "courses": []
    }
    
    for course in merged_context.get("courses", []):
        # í•„ìˆ˜ í•„ë“œ ë³´ì¥
        normalized_course = {
            "course_name": course.get("course_name", ""),
            "professor": course.get("professor", ""),
            "department": course.get("department", ""),
            "rating": float(course.get("rating", 0.0)),
            "review_count": int(course.get("review_count", 0)),
            "reviews": []
        }
        
        # ë¦¬ë·° ì •ê·œí™” (í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ)
        reviews = course.get("reviews", [])
        for review in reviews:
            review_text = review.get("text", "")
            # ë¦¬ë·° í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì²« 200ìë§Œ ì‚¬ìš©
            if len(review_text) > 200:
                review_text = review_text[:200] + "..."
            
            normalized_review = {
                "text": review_text,
                "review_id": review.get("review_id", ""),
                "sentiment": review.get("sentiment")
            }
            normalized_course["reviews"].append(normalized_review)
        
        # review_countë¥¼ ì‹¤ì œ ë¦¬ë·° ê°œìˆ˜ë¡œ ì—…ë°ì´íŠ¸
        normalized_course["review_count"] = len(normalized_course["reviews"])
        
        normalized["courses"].append(normalized_course)
    
    return normalized

def synthesize_answer_with_llm(user_query: str, merged_context: Dict[str, Any]) -> str:
    """
    LLM ìµœì¢… ì‘ë‹µ ìƒì„± (Gemini)
    
    Args:
        user_query: ì‚¬ìš©ì ì§ˆë¬¸
        merged_context: merge_results()ì˜ ì¶œë ¥
        
    Returns:
        str: Geminiê°€ ìƒì„±í•œ ìµœì¢… ë‹µë³€
    """
    try:
        # ì»¨í…ìŠ¤íŠ¸ ì •ê·œí™”
        normalized_context = normalize_context(merged_context)
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸:
{user_query}

ì•„ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ê°•ì˜ ì •ë³´ ë° ê°•ì˜í‰ ë¦¬ë·° ë°ì´í„°ì…ë‹ˆë‹¤.
ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1) ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ì— ë§ëŠ” ì¶”ì²œ ë˜ëŠ” ì¡°ì–¸ ì œì‹œ
2) ê°•ì˜ íŠ¹ì§• ìš”ì•½
3) êµìˆ˜ë‹˜ì˜ ê°•ì˜ ìŠ¤íƒ€ì¼/íŠ¹ì§• ìš”ì•½
4) í•„ìš”í•œ ê²½ìš° ê°•ì˜í‰ì„ ê¸°ë°˜ìœ¼ë¡œ ì¥ì /ë‹¨ì  ì •ë¦¬
5) ì—¬ëŸ¬ ê°•ì˜ê°€ ìˆì„ ê²½ìš° ì •í™•ë„ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìµœëŒ€ 5ê°œê¹Œì§€ ë¹„êµ í›„ ì•ˆë‚´
6) ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ ê²ƒ
7) JSONì´ ì•„ë‹ˆë¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€ ìƒì„±
8) ê°•ì˜í‰ì— ê³¼ë„í•˜ê²Œ ë¹„ë‚œì ì¸ ë‚´ìš©ì´ë‚˜ ë¶€ì •ì ì¸ ë‚´ìš©ì€ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ (êµìˆ˜ë‹˜ì´ ë³¼ ìˆ˜ë„ ìˆë‹¤ê³  ìƒê°í•˜ê¸°)

ê°•ì˜ ë°ì´í„°(JSON):
{json.dumps(normalized_context, ensure_ascii=False, indent=2)}"""

        # Gemini ëª¨ë¸ í˜¸ì¶œ
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        
        # ì‘ë‹µ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ (ai_api.pyì˜ generate_gemini_responseì™€ ë™ì¼í•œ ë°©ì‹)
        # getattrë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼í•˜ê³ , ì‹¤íŒ¨ ì‹œ str(response)ë¡œ fallback
        response_text = getattr(response, 'text', None) or str(response)
        
        # ë¹ˆ ì‘ë‹µì´ê±°ë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ì¸ ê²½ìš° ì²˜ë¦¬
        if not response_text or len(response_text.strip()) == 0:
            # candidatesì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
            if response.candidates and len(response.candidates) > 0:
                candidate = response.candidates[0]
                finish_reason = getattr(candidate, 'finish_reason', None)
                
                # finish_reason í™•ì¸ (1=STOP ì •ìƒ, 2=MAX_TOKENS, 3=SAFETY, 4=RECITATION)
                if finish_reason == 3:  # SAFETY - ì•ˆì „ í•„í„°ì— ê±¸ë¦¼
                    return "ì£„ì†¡í•©ë‹ˆë‹¤. ì•ˆì „ í•„í„°ë¡œ ì¸í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ì£¼ì„¸ìš”."
                elif finish_reason == 2:  # MAX_TOKENS - í† í° ì œí•œ
                    return "ë‹µë³€ì´ ë„ˆë¬´ ê¸¸ì–´ì„œ ì¼ë¶€ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤."
                elif finish_reason == 4:  # RECITATION - ì¸ìš© ë¬¸ì œ
                    return "ì¸ìš© ë¬¸ì œë¡œ ì¸í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                # partsì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if hasattr(candidate, 'content') and candidate.content:
                    if hasattr(candidate.content, 'parts') and candidate.content.parts:
                        parts_text = []
                        for part in candidate.content.parts:
                            if hasattr(part, 'text') and part.text:
                                parts_text.append(part.text)
                        if parts_text:
                            return '\n'.join(parts_text)
            
            return "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        return response_text
        
    except Exception as e:
        print(f"âŒ LLM ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RAG Chat API ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 
# ìš”ì²­ ì˜ˆì‹œ:
# POST /api/v2/rag/chat
# Content-Type: application/json
# {
#   "query": "ë°ì´í„°ë² ì´ìŠ¤ ê°•ì˜ ì¶”ì²œí•´ì¤˜"
# }
#
# ì‘ë‹µ ì˜ˆì‹œ (ì„±ê³µ):
# {
#   "answer": "ë‹µë³€ ìƒì„± ì¤‘...",
#   "debug": {
#     "intent": {
#       "needs_structured_filter": false,
#       "filters": {},
#       "semantic_query": "ë°ì´í„°ë² ì´ìŠ¤ ê°•ì˜ ì¶”ì²œí•´ì¤˜"
#     },
#     "mongo_candidates": 0,
#     "pinecone_hits": 0
#   }
# }
@app.route("/api/v2/rag/chat", methods=["POST"])
def rag_chat():
    """RAG ê¸°ë°˜ ì±—ë´‡ API"""
    try:
        body = request.get_json()
        user_query = body.get("query", "").strip()
        
        if not user_query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # Step 1: ì§ˆë¬¸ ë¶„ì„ (Structured / Semantic ë¶„ë¦¬)
        intent = classify_query_intent(user_query)
        
        # Step 2: êµ¬ì¡°ì  í•„í„° í•„ìš” ì—¬ë¶€ í™•ì¸
        if intent.needs_structured_filter:
            mongo_candidates = filter_from_mongodb(intent.filters)
        else:
            mongo_candidates = None
        
        # Step 3: Pinecone ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
        pinecone_results = semantic_search_pinecone(
            query=intent.semantic_query,
            candidates=mongo_candidates
        )
        
        # Step 4: ë‘ ê²°ê³¼ë¥¼ merge â†’ ê°•ì˜ ì •ë³´ + ë¦¬ë·° ì •ë³´ í†µí•©
        merged_context = merge_results(
            mongo_candidates,
            pinecone_results
        )
        
        # Step 5: LLM ìµœì¢… ì‘ë‹µ ìƒì„± (Gemini)
        final_answer = synthesize_answer_with_llm(
            user_query,
            merged_context
        )
        
        # Step 6: ì‘ë‹µ ë°˜í™˜
        return jsonify({
            "answer": final_answer,
            "debug": {
                "intent": intent.model_dump(),  # Pydantic BaseModelì„ dictë¡œ ë³€í™˜
                "mongo_candidates": len(mongo_candidates) if mongo_candidates else 0,
                "pinecone_hits": len(pinecone_results)
            }
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/api/v2/rag/test/intent", methods=["POST"])
def test_classify_intent():
    """
    ì§ˆë¬¸ ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/intent
    Content-Type: application/json
    {
      "query": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜"
    }
    
    ì‘ë‹µ ì˜ˆì‹œ:
    {
      "query": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜",
      "intent": {
        "needs_structured_filter": true,
        "filters": {
          "department": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼",
          "course_type": "ì „í•„"
        },
        "semantic_query": "ê³¼ëª© ì¶”ì²œí•´ì¤˜"
      }
    }
    """
    try:
        body = request.get_json() or {}
        user_query = body.get("query", "").strip()
        
        if not user_query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # ì§ˆë¬¸ ì˜ë„ ë¶„ì„
        intent = classify_query_intent(user_query)
        
        return jsonify({
            "query": user_query,
            "intent": intent.model_dump()
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/v2/rag/test/intent/batch", methods=["POST"])
def test_classify_intent_batch():
    """
    ì—¬ëŸ¬ ì§ˆë¬¸ì„ í•œë²ˆì— í…ŒìŠ¤íŠ¸í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/intent/batch
    Content-Type: application/json
    {
      "queries": [
        "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜",
        "ì´ë²ˆ í•™ê¸°ì— ì—´ë¦¬ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê°•ì˜ ì¶”ì²œí•´ì¤˜",
        "ì†ê²½ì•„ êµìˆ˜ë‹˜ ì–´ë•Œ?",
        "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜"
      ]
    }
    """
    try:
        body = request.get_json() or {}
        queries = body.get("queries", [])
        
        if not queries or not isinstance(queries, list):
            return jsonify({"error": "queries íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (ë°°ì—´)"}), 400
        
        results = []
        for query in queries:
            try:
                intent = classify_query_intent(query)
                results.append({
                    "query": query,
                    "intent": intent.model_dump(),
                    "success": True
                })
            except Exception as e:
                results.append({
                    "query": query,
                    "error": str(e),
                    "success": False
                })
        
        return jsonify({
            "total": len(queries),
            "results": results
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/v2/rag/test/mongodb", methods=["POST"])
def test_mongodb_filter():
    """
    MongoDB í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ (ì§ˆë¬¸ìœ¼ë¡œ ìë™ ë¶„ì„)
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/mongodb
    Content-Type: application/json
    {
      "query": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜"
    }
    """
    try:
        body = request.get_json() or {}
        user_query = body.get("query", "").strip()
        
        if not user_query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # Intent ë¶„ì„ í›„ filters ì¶”ì¶œ
        intent = classify_query_intent(user_query)
        filters = intent.filters
        
        # êµ¬ì¡°ì  í•„í„°ê°€ ë¶ˆí•„ìš”í•œ ê²½ìš°
        if not intent.needs_structured_filter or not filters:
            return jsonify({
                "query": user_query,
                "intent": intent.model_dump(),
                "message": "êµ¬ì¡°ì  í•„í„°ê°€ ë¶ˆí•„ìš”í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤. MongoDB í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.",
                "filters": {},
                "count": 0,
                "results": []
            })
        
        # MongoDB í•„í„°ë§ ì‹¤í–‰
        results = filter_from_mongodb(filters)
        
        return jsonify({
            "query": user_query,
            "intent": intent.model_dump(),
            "filters": filters,
            "count": len(results) if results else 0,
            "results": results or []
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/v2/rag/test/pinecone", methods=["POST"])
def test_pinecone_search():
    """
    Pinecone ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/pinecone
    Content-Type: application/json
    {
      "query": "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜",
      "candidates": [
        {"course_name": "ë°ì´í„°ë² ì´ìŠ¤"},
        {"course_name": "ìë£Œêµ¬ì¡°"}
      ],
      "top_k": 5
    }
    """
    try:
        body = request.get_json() or {}
        query = body.get("query", "").strip()
        candidates = body.get("candidates", None)
        top_k = body.get("top_k", 5)
        
        if not query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # Pinecone ê²€ìƒ‰ ì‹¤í–‰
        results = semantic_search_pinecone(query, candidates, top_k)
        
        return jsonify({
            "query": query,
            "candidates_count": len(candidates) if candidates else 0,
            "top_k": top_k,
            "results_count": len(results),
            "results": results
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/v2/rag/test/full", methods=["POST"])
def test_full_rag_pipeline():
    """
    ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ (ë‹µë³€ ìƒì„± ì œì™¸)
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/full
    Content-Type: application/json
    {
      "query": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜"
    }
    """
    try:
        body = request.get_json() or {}
        user_query = body.get("query", "").strip()
        
        if not user_query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # Step 1: ì§ˆë¬¸ ë¶„ì„
        intent = classify_query_intent(user_query)
        
        # Step 2: MongoDB í•„í„°ë§
        mongo_candidates = None
        if intent.needs_structured_filter:
            mongo_candidates = filter_from_mongodb(intent.filters)
        
        # Step 3: Pinecone ê²€ìƒ‰
        pinecone_results = semantic_search_pinecone(
            query=intent.semantic_query,
            candidates=mongo_candidates
        )
        
        # Step 4: ê²°ê³¼ ë³‘í•©
        merged_context = merge_results(mongo_candidates, pinecone_results)
        
        return jsonify({
            "query": user_query,
            "intent": intent.model_dump(),
            "mongo_candidates": {
                "count": len(mongo_candidates) if mongo_candidates else 0,
                "courses": mongo_candidates[:5] if mongo_candidates else []  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            },
            "pinecone_results": {
                "count": len(pinecone_results),
                "reviews": pinecone_results[:5]  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            },
            "merged_context": merged_context
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5005, debug=True)
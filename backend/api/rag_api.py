#!/usr/bin/env python3
"""Pinecone ê°•ì˜ ë°ì´í„° API"""

from flask import Flask, jsonify, request
from flask_cors import CORS
import os
import json
import sys
from dotenv import load_dotenv
from pinecone import Pinecone
from collections import defaultdict
from sentence_transformers import SentenceTransformer
from langchain_pinecone import PineconeVectorStore
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
import google.generativeai as genai

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from backend.api import get_mongo_db

# LangChain Embeddings import (ë²„ì „ì— ë”°ë¼ ê²½ë¡œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
try:
    from langchain_core.embeddings import Embeddings
except ImportError:
    try:
        from langchain.embeddings.base import Embeddings
    except ImportError:
        from langchain.embeddings import Embeddings

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
CORS(app)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Pinecone ì—°ê²°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')
PINECONE_INDEX = os.getenv('PINECONE_INDEX', 'courses-dev')

pc = Pinecone(api_key=PINECONE_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Embedding ëª¨ë¸ - multilingual-e5-base
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# embedding_model = SentenceTransformer("intfloat/multilingual-e5-base")
embedding_model = SentenceTransformer("jhgan/ko-sroberta-multitask")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangChain Embeddings ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SentenceTransformerEmbeddings(Embeddings):
    """SentenceTransformerë¥¼ LangChain Embeddings ì¸í„°í˜ì´ìŠ¤ë¡œ ë˜í•‘"""
    
    def __init__(self, model: SentenceTransformer):
        self.model = model
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œ ì„ë² ë”© (passage í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©)"""
        # E5 ëª¨ë¸ì€ passage í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©
        formatted = [f"passage: {text}" for text in texts]
        embeddings = self.model.encode(formatted, normalize_embeddings=True)
        return embeddings.tolist()
    
    def embed_query(self, text: str) -> List[float]:
        """ì¿¼ë¦¬ ì„ë² ë”© (query í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©)"""
        # E5 ëª¨ë¸ì€ query í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©
        formatted = f"query: {text}"
        embedding = self.model.encode([formatted], normalize_embeddings=True)
        return embedding[0].tolist()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VectorStore ì´ˆê¸°í™” í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_vectorstore() -> PineconeVectorStore:
    """
    Pinecone VectorStore ì´ˆê¸°í™”
    upsertì™€ ë™ì¼í•œ êµ¬ì¡°ë¡œ ìƒì„±
    """
    embeddings = SentenceTransformerEmbeddings(embedding_model)
    vectorstore = PineconeVectorStore(
        index_name=PINECONE_INDEX,
        embedding=embeddings
    )
    return vectorstore

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangChain Pinecone VectorStore (ì „ì—­ ì¸ìŠ¤í„´ìŠ¤)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
vectorstore = init_vectorstore()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini LLM í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

genai.configure(api_key=GEMINI_API_KEY)

def call_gemini(prompt):
    model = genai.GenerativeModel("gemini-2.5-flash")
    response = model.generate_content(prompt)
    return response.text

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Intent í´ë˜ìŠ¤ (ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ê²°ê³¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class QueryIntent(BaseModel):
    """ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ê²°ê³¼"""
    needs_structured_filter: bool
    filters: Dict[str, Any]
    semantic_query: str
    comparison_targets: Optional[Dict[str, Any]] = None  # ë¹„êµ ëŒ€ìƒ ì •ë³´
    # comparison_targets êµ¬ì¡°:
    # {
    #   "course_names": List[str],  # ë¹„êµ ëŒ€ìƒ ê°•ì˜ëª… ë¦¬ìŠ¤íŠ¸
    #   "professors": List[str],     # ë¹„êµ ëŒ€ìƒ êµìˆ˜ëª… ë¦¬ìŠ¤íŠ¸
    #   "comparison_type": str       # "course" | "professor" | "both" | None
    # }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper í•¨ìˆ˜ë“¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def classify_query_intent(user_query: str) -> QueryIntent:
    """
    ì§ˆë¬¸ ì˜ë„ ë¶„ì„ (Structured / Semantic ë¶„ë¦¬)
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  êµ¬ì¡°ì  í•„í„°ì™€ ì˜ë¯¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë¶„ë¦¬
    
    Args:
        user_query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        QueryIntent: ë¶„ì„ëœ ì˜ë„ ì •ë³´
    """
    try:
        # Gemini í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:

1. êµ¬ì¡°ì  í•„í„° í•„ìš” ì—¬ë¶€ (needs_structured_filter):
   - MongoDB courseì— ìˆëŠ” í•„ë“œë¡œ í•„í„°ë§ì´ í•„ìš”í•œì§€ íŒë‹¨
   - ì˜ˆ: "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜" â†’ true (department, course_type í•„í„° í•„ìš”)
   - ì˜ˆ: "ë°ì´í„°ë² ì´ìŠ¤ ë“¤ì„ê¹Œ ë§ê¹Œ?" â†’ true (course_name í•„í„° í•„ìš”)
   - ì˜ˆ: "ì´ë²ˆ í•™ê¸°ì— ì—´ë¦¬ëŠ” ì‰¬ìš´ ì „ê³µ ì„ íƒ(ì „ì„ ) ê³¼ëª© ì¤‘ì— ë¹„ëŒ€ë©´ ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ true (semester, lecture_type, course_type í•„í„° í•„ìš”)
   - ì˜ˆ: "ì†ê²½ì•„ êµìˆ˜ë‹˜ ì–´ë•Œ?" â†’ true (professor í•„í„° í•„ìš”)
   - ì˜ˆ: "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ false (êµ¬ì¡°ì  í•„í„° ë¶ˆí•„ìš”)
   - ì˜ˆ: "ë‚´ ê°œë°œ ì‹¤ë ¥ì— ì§„ì§œ ë„ì›€ë˜ëŠ” ê°•ì˜ ìˆì„ê¹Œ?" â†’ false (êµ¬ì¡°ì  í•„í„° ë¶ˆí•„ìš”)

2. MongoDB í•„í„° (filters):
   - êµ¬ì¡°ì  í•„í„°ê°€ í•„ìš”í•œ ê²½ìš°, ì¶”ì¶œ ê°€ëŠ¥í•œ í•„ë“œë“¤ì„ key-value í˜•íƒœë¡œ ì œê³µ
   - ê°€ëŠ¥í•œ í•„ë“œ: course_name, professor, department, target_grade, semester, credits, lecture_time, lecture_method, course_type, subject_type
   - departmentëŠ” "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼"ë°–ì— ì˜¬ ìˆ˜ ì—†ê³ , course_typeëŠ” "ì „í•„", "ì „ì„ "ë°–ì— ì˜¬ ìˆ˜ ì—†ìŒ. lecture_timeëŠ” "ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ"ë°–ì— ì˜¬ ìˆ˜ ì—†ìŒ.
   - ì˜ˆ: {{"course_name": "ë°ì´í„°ë² ì´ìŠ¤"}}, {{"department": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼", "course_type": "ì „ì„ "}}
   - êµ¬ì¡°ì  í•„í„°ê°€ ë¶ˆí•„ìš”í•˜ë©´ ë¹ˆ ê°ì²´ {{}} ë°˜í™˜

3. ì˜ë¯¸ ê²€ìƒ‰ ì¿¼ë¦¬ (semantic_query):
   - êµ¬ì¡°ì  í•„í„° ë¶€ë¶„ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ìì—°ì–´ ì§ˆë¬¸ì„ ì •ì œ
   - êµ¬ì¡°ì  í•„í„°ê°€ í•„ìš”í•œ ê²½ìš°: í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„(ê³¼ëª©ëª…, êµìˆ˜ëª…, í•™ê³¼ëª…, í•™ê¸°, ìˆ˜ì—…ë°©ì‹ ë“±)ì„ ì œê±°í•˜ê³  ë‚˜ë¨¸ì§€ ì˜ë¯¸ ìˆëŠ” ì§ˆë¬¸ë§Œ ë‚¨ê¹€
   - êµ¬ì¡°ì  í•„í„°ê°€ ë¶ˆí•„ìš”í•œ ê²½ìš°: ì›ë³¸ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
   - ì¤‘ìš”: semantic_queryê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ê°€ ë¶ˆëª…í™•í•œ ê²½ìš°(ì˜ˆ: "ë“¤ì„ê¹Œ ë§ê¹Œ?"), ê°•ì˜í‰ì´ë‚˜ ê°•ì˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì˜ë¯¸ë¥¼ í™•ì¥í•˜ê±°ë‚˜, ì¥ë‹¨ì ì„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ê²€ìƒ‰ ë° ì •ë¦¬ ìˆ˜í–‰
   - ì˜ˆ: "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜" â†’ "ê³¼ëª© ì¶”ì²œí•´ì¤˜" (department, course_type ì œê±°)
   - ì˜ˆ: "SWìº¡ìŠ¤í†¤ë””ìì¸ ë“¤ì„ê¹Œ ë§ê¹Œ?" â†’ "ê°•ì˜ ì–´ë•Œ" ë˜ëŠ” "ê°•ì˜ ì¥ë‹¨ì  ì •ë¦¬í•´ì¤˜" (course_name ì œê±°, ì˜ë¯¸ í™•ì¥)
   - ì˜ˆ: "ì´ë²ˆ í•™ê¸°ì— ì—´ë¦¬ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ "ê°•ì˜ ì¶”ì²œí•´ì¤˜" (course_name, semester ì œê±°)
   - ì˜ˆ: "ì´ë²ˆ í•™ê¸°ì— ì—´ë¦¬ëŠ” ì‰¬ìš´ ì „ê³µ ì„ íƒ(ì „ì„ ) ê³¼ëª© ì¤‘ì— ë¹„ëŒ€ë©´ ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ "ì‰¬ìš´ ê°•ì˜ ì¶”ì²œí•´ì¤˜" (semester, lecture_type, course_type ì œê±°)
   - ì˜ˆ: "ì†ê²½ì•„ êµìˆ˜ë‹˜ ì–´ë•Œ?" â†’ "êµìˆ˜ë‹˜ ê°•ì˜ ì–´ë•Œ" (professor ì œê±°, ì˜ë¯¸ í™•ì¥)
   - ì˜ˆ: "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜" (êµ¬ì¡°ì  í•„í„° ì—†ìŒ, ì›ë³¸ ê·¸ëŒ€ë¡œ)
   - ì˜ˆ: "ë‚´ ê°œë°œ ì‹¤ë ¥ì— ì§„ì§œ ë„ì›€ë˜ëŠ” ê°•ì˜ ìˆì„ê¹Œ?" â†’ "ë‚´ ê°œë°œ ì‹¤ë ¥ì— ì§„ì§œ ë„ì›€ë˜ëŠ” ê°•ì˜ ìˆì„ê¹Œ?" (êµ¬ì¡°ì  í•„í„° ì—†ìŒ, ì›ë³¸ ê·¸ëŒ€ë¡œ)

4. ë¹„êµ ëŒ€ìƒ ì¶”ì¶œ (comparison_targets):
   - ì§ˆë¬¸ì—ì„œ ë¹„êµí•˜ê³  ìˆëŠ” ê°•ì˜ëª…ê³¼ êµìˆ˜ëª…ì„ ì¶”ì¶œ
   - ë¹„êµ íƒ€ì… íŒë‹¨:
     * "course": ì—¬ëŸ¬ ê°•ì˜ë¥¼ ë¹„êµí•˜ëŠ” ê²½ìš° (ì˜ˆ: "ê¸°ê³„í•™ìŠµê³¼ ì¸ê³µì§€ëŠ¥ì˜ ì°¨ì´")
     * "professor": í•œ ê°•ì˜ì˜ ì—¬ëŸ¬ êµìˆ˜ë¥¼ ë¹„êµí•˜ëŠ” ê²½ìš° (ì˜ˆ: "ì•Œê³ ë¦¬ì¦˜ ê°•ì˜ êµìˆ˜ë‹˜ë³„ ì°¨ì´ì ")
     * "both": ì—¬ëŸ¬ ê°•ì˜ì˜ ì—¬ëŸ¬ êµìˆ˜ë¥¼ ë¹„êµí•˜ëŠ” ê²½ìš°
     * null: ë¹„êµ ì§ˆì˜ê°€ ì•„ë‹Œ ê²½ìš°
   - course_names: ë¹„êµ ëŒ€ìƒ ê°•ì˜ëª… ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ [])
   - professors: ë¹„êµ ëŒ€ìƒ êµìˆ˜ëª… ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ [])
   - ì˜ˆ: "ì•Œê³ ë¦¬ì¦˜ ê°•ì˜ êµìˆ˜ë‹˜ë³„ ì°¨ì´ì  ì•Œë ¤ì¤˜" â†’ {{"course_names": ["ì•Œê³ ë¦¬ì¦˜"], "professors": [], "comparison_type": "professor"}}
   - ì˜ˆ: "ê¸°ê³„í•™ìŠµê³¼ ì¸ê³µì§€ëŠ¥ì˜ ì°¨ì´ê°€ ë­ì•¼?" â†’ {{"course_names": ["ê¸°ê³„í•™ìŠµ", "ì¸ê³µì§€ëŠ¥"], "professors": [], "comparison_type": "course"}}
   - ì˜ˆ: "ê°ì²´ì§€í–¥í”„ë¡œê·¸ë˜ë° ì–´ëŠ êµìˆ˜ë‹˜ì´ ì¢‹ì•„?" â†’ {{"course_names": ["ê°ì²´ì§€í–¥í”„ë¡œê·¸ë˜ë°"], "professors": [], "comparison_type": "professor"}}
   - ì˜ˆ: "ë°ì´í„°ë² ì´ìŠ¤ì— ëŒ€í•´ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜" â†’ {{"course_names": [], "professors": [], "comparison_type": null}}

ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ì¶”ê°€ ì„¤ëª… ì—†ì´):
{{
    "needs_structured_filter": true/false,
    "filters": {{}},
    "semantic_query": "ì •ì œëœ ì§ˆë¬¸",
    "comparison_targets": {{
        "course_names": [],
        "professors": [],
        "comparison_type": null
    }}
}}"""

        # Gemini ëª¨ë¸ í˜¸ì¶œ
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()
        
        # JSON íŒŒì‹±
        intent_data = json.loads(response_text)
        
        # QueryIntent ê°ì²´ ìƒì„±
        comparison_targets = intent_data.get("comparison_targets")
        if comparison_targets is None:
            comparison_targets = {
                "course_names": [],
                "professors": [],
                "comparison_type": None
            }
        
        return QueryIntent(
            needs_structured_filter=intent_data.get("needs_structured_filter", False),
            filters=intent_data.get("filters", {}),
            semantic_query=intent_data.get("semantic_query", user_query),
            comparison_targets=comparison_targets
        )
        
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"   Gemini ì‘ë‹µ: {response_text if 'response_text' in locals() else 'N/A'}")
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return QueryIntent(
            needs_structured_filter=False,
            filters={},
            semantic_query=user_query,
            comparison_targets={
                "course_names": [],
                "professors": [],
                "comparison_type": None
            }
        )
    except Exception as e:
        print(f"âŒ ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return QueryIntent(
            needs_structured_filter=False,
            filters={},
            semantic_query=user_query,
            comparison_targets={
                "course_names": [],
                "professors": [],
                "comparison_type": None
            }
        )

def filter_from_mongodb(filters: Dict[str, Any]) -> Optional[List[Dict[str, Any]]]:
    """
    MongoDBì—ì„œ êµ¬ì¡°ì  í•„í„°ë¡œ ê°•ì˜ ê²€ìƒ‰
    
    Args:
        filters: í•„í„° ë”•ì…”ë„ˆë¦¬ (department, course_name, professor, 
                semester, credits, course_type, subject_type, lecture_time, lecture_method ë“±)
        
    Returns:
        List[Dict]: ê°•ì˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (course_name, professor, department ë“± í¬í•¨)
    """
    try:
        if not filters:
            return None
        
        db = get_mongo_db()
        collection = db.courses
        
        # ë™ì  ì¿¼ë¦¬ êµ¬ì„±
        query = {}
        
        # department í•„í„°
        if "department" in filters:
            query["department"] = {"$regex": filters["department"], "$options": "i"}
        
        # course_name í•„í„°
        if "course_name" in filters:
            query["course_name"] = {"$regex": filters["course_name"], "$options": "i"}
        
        # professor í•„í„°
        if "professor" in filters:
            query["professor"] = {"$regex": filters["professor"], "$options": "i"}
        
        # semester í•„í„° (yearì™€ ë³„ë„)
        if "semester" in filters:
            query["semester"] = filters["semester"]
        
        # credits í•„í„°
        if "credits" in filters:
            query["credits"] = filters["credits"]
        
        # course_type í•„í„° (ì „í•„, ì „ì„  ë“±)
        if "course_type" in filters:
            query["course_type"] = {"$regex": filters["course_type"], "$options": "i"}
        
        # subject_type í•„í„°
        if "subject_type" in filters:
            query["subject_type"] = {"$regex": filters["subject_type"], "$options": "i"}
        
        # lecture_time í•„í„°
        if "lecture_time" in filters:
            query["lecture_time"] = {"$regex": filters["lecture_time"], "$options": "i"}
        
        # lecture_method í•„í„° (ë¹„ëŒ€ë©´, ëŒ€ë©´ ë“±)
        if "lecture_method" in filters:
            query["lecture_method"] = {"$regex": filters["lecture_method"], "$options": "i"}
        
        if not query:
            return None
        
        # MongoDB ê²€ìƒ‰ ì‹¤í–‰
        cursor = collection.find(query).limit(100)  # ìµœëŒ€ 100ê°œ
        results = []
        
        for doc in cursor:
            course_data = {
                "course_name": doc.get("course_name", ""),
                "professor": doc.get("professor", ""),
                "department": doc.get("department", ""),
                "semester": doc.get("semester", ""),
                "credits": doc.get("credits", 3),
                "course_type": doc.get("course_type", ""),
                "subject_type": doc.get("subject_type", ""),
                "lecture_time": doc.get("lecture_time", ""),
                "lecture_method": doc.get("lecture_method", ""),
                "course_id": doc.get("course_id", ""),
                "rating": doc.get("rating", 0.0),
                "average_rating": doc.get("average_rating", 0.0),
                "total_reviews": doc.get("total_reviews", 0)
            }
            results.append(course_data)
        
        print(f"âœ… MongoDBì—ì„œ {len(results)}ê°œ ê°•ì˜ ë°œê²¬ (í•„í„°: {filters})")
        return results if results else None
        
    except Exception as e:
        print(f"âŒ MongoDB í•„í„°ë§ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

def semantic_search_pinecone(query: str, candidates: Optional[List[Dict[str, Any]]] = None, top_k: int = 5, comparison_targets: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
    """
    Pinecone ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (metadata í•„í„° ì§€ì›, ë¹„êµ ëŒ€ìƒ ë³´ì¥)
    
    Args:
        query: ê²€ìƒ‰í•  ì¿¼ë¦¬ í…ìŠ¤íŠ¸
        candidates: MongoDB í›„ë³´ ëª©ë¡ (course_name ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ í•„í„°ë§ì— ì‚¬ìš©)
        top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
        comparison_targets: ë¹„êµ ëŒ€ìƒ ì •ë³´ (course_names, professors, comparison_type)
    
    Returns:
        List[Dict]: metadata, textë¥¼ í¬í•¨í•œ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        [
            {
                "text": "ë¬¸ì„œ ë‚´ìš©",
                "metadata": {...}
            },
            ...
        ]
    """
    try:
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = embedding_model.encode([f"query: {query}"], normalize_embeddings=True)[0].tolist()
        
        index = pc.Index(PINECONE_INDEX)
        
        # ë¹„êµ ëŒ€ìƒ ë³´ì¥ ê²€ìƒ‰ ê²°ê³¼
        guaranteed_results = []
        guaranteed_keys = set()  # ì¤‘ë³µ ì œê±°ìš©: (course_name, professor) íŠœí”Œ
        
        if comparison_targets:
            course_names = comparison_targets.get("course_names", [])
            professors = comparison_targets.get("professors", [])
            comparison_type = comparison_targets.get("comparison_type")
            
            if comparison_type in ["course", "professor", "both"]:
                print(f"ğŸ” ë¹„êµ ëŒ€ìƒ ë³´ì¥ ê²€ìƒ‰: course_names={course_names}, professors={professors}, type={comparison_type}")
                
                # ê° ê°•ì˜ëª…ë³„ë¡œ ìµœì†Œ 1ê°œì”© ê²€ìƒ‰
                for course_name in course_names:
                    if not course_name:
                        continue
                    
                    course_filter = {"course_name": {"$eq": course_name}}
                    try:
                        course_response = index.query(
                            vector=query_embedding,
                            top_k=1,
                            include_metadata=True,
                            filter=course_filter
                        )
                        
                        for match in course_response.matches:
                            meta = match.metadata
                            key = (meta.get("course_name", ""), meta.get("professor", ""))
                            if key not in guaranteed_keys:
                                guaranteed_results.append({
                                    "text": meta.get("text", ""),
                                    "metadata": meta
                                })
                                guaranteed_keys.add(key)
                    except Exception as e:
                        print(f"âš ï¸ ê°•ì˜ëª… '{course_name}' ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                
                # ê° êµìˆ˜ëª…ë³„ë¡œ ìµœì†Œ 1ê°œì”© ê²€ìƒ‰ (êµìˆ˜ ë¹„êµì¸ ê²½ìš°)
                if comparison_type in ["professor", "both"]:
                    for professor in professors:
                        if not professor:
                            continue
                        
                        professor_filter = {"professor": {"$eq": professor}}
                        try:
                            professor_response = index.query(
                                vector=query_embedding,
                                top_k=1,
                                include_metadata=True,
                                filter=professor_filter
                            )
                            
                            for match in professor_response.matches:
                                meta = match.metadata
                                key = (meta.get("course_name", ""), meta.get("professor", ""))
                                if key not in guaranteed_keys:
                                    guaranteed_results.append({
                                        "text": meta.get("text", ""),
                                        "metadata": meta
                                    })
                                    guaranteed_keys.add(key)
                        except Exception as e:
                            print(f"âš ï¸ êµìˆ˜ëª… '{professor}' ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    
                    # ê°•ì˜+êµìˆ˜ ì¡°í•©ë³„ë¡œ ìµœì†Œ 1ê°œì”© ê²€ìƒ‰ (êµìˆ˜ ë¹„êµì¸ ê²½ìš°)
                    if course_names and not professors:
                        # course_namesëŠ” ìˆì§€ë§Œ professorsê°€ ì—†ëŠ” ê²½ìš°, í•´ë‹¹ ê°•ì˜ì˜ ëª¨ë“  êµìˆ˜ì— ëŒ€í•´ ê²€ìƒ‰
                        for course_name in course_names:
                            if not course_name:
                                continue
                            
                            # í•´ë‹¹ ê°•ì˜ì˜ êµìˆ˜ë“¤ì„ ì°¾ê¸° ìœ„í•´ ë¨¼ì € ê²€ìƒ‰
                            course_filter = {"course_name": {"$eq": course_name}}
                            try:
                                course_response = index.query(
                                    vector=query_embedding,
                                    top_k=10,  # ì—¬ëŸ¬ êµìˆ˜ ì°¾ê¸° ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
                                    include_metadata=True,
                                    filter=course_filter
                                )
                                
                                # êµìˆ˜ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê° êµìˆ˜ë‹¹ ìµœì†Œ 1ê°œì”©
                                professors_found = {}
                                for match in course_response.matches:
                                    meta = match.metadata
                                    prof_name = meta.get("professor", "")
                                    if prof_name and prof_name not in professors_found:
                                        key = (meta.get("course_name", ""), prof_name)
                                        if key not in guaranteed_keys:
                                            professors_found[prof_name] = {
                                                "text": meta.get("text", ""),
                                                "metadata": meta
                                            }
                                            guaranteed_keys.add(key)
                                
                                for prof_result in professors_found.values():
                                    guaranteed_results.append(prof_result)
                            except Exception as e:
                                print(f"âš ï¸ ê°•ì˜ '{course_name}' êµìˆ˜ë³„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        # ì¼ë°˜ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (ë³´ì¥ëœ ê²°ê³¼ì™€ ë³‘í•©)
        pinecone_filter = {}
        
        if candidates:
            # candidatesì—ì„œ course_name ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            candidate_course_names = []
            for candidate in candidates:
                course_name = candidate.get("course_name", "")
                if course_name:
                    candidate_course_names.append(course_name)
            
            if candidate_course_names:
                # Pinecone metadata í•„í„°: course_nameì´ candidates ì¤‘ í•˜ë‚˜ì™€ ì¼ì¹˜
                pinecone_filter = {
                    "course_name": {"$in": candidate_course_names}
                }
                print(f"ğŸ” Pinecone í•„í„° ì ìš©: {len(candidate_course_names)}ê°œ course_name")
        
        # ì¼ë°˜ ê²€ìƒ‰ ì‹¤í–‰ (ë³´ì¥ëœ ê²°ê³¼ ì œì™¸)
        remaining_k = max(1, top_k - len(guaranteed_results))
        # ë¹„êµ ëŒ€ìƒì´ ìˆì„ ë•Œë§Œ ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
        has_comparison = comparison_targets and comparison_targets.get("comparison_type") in ["course", "professor", "both"]
        query_top_k = remaining_k * 2 if has_comparison else remaining_k
        query_kwargs = {
            "vector": query_embedding,
            "top_k": query_top_k,
            "include_metadata": True
        }
        if pinecone_filter:
            query_kwargs["filter"] = pinecone_filter
        
        query_response = index.query(**query_kwargs)
        
        # ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        semantic_results = []
        for match in query_response.matches:
            meta = match.metadata
            key = (meta.get("course_name", ""), meta.get("professor", ""))
            if key not in guaranteed_keys:
                semantic_results.append({
                    "text": meta.get("text", ""),
                    "metadata": meta
                })
                guaranteed_keys.add(key)
        
        # ë³´ì¥ëœ ê²°ê³¼ + ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© (ìµœëŒ€ top_kê°œ)
        all_results = guaranteed_results + semantic_results
        final_results = all_results[:top_k]
        
        print(f"âœ… Pineconeì—ì„œ {len(final_results)}ê°œ ê°•ì˜í‰ ë°œê²¬ (ë³´ì¥: {len(guaranteed_results)}, ì¼ë°˜: {len(semantic_results)})")
        return final_results
        
    except Exception as e:
        print(f"âŒ Pinecone ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return []

def merge_results(mongo_candidates: Optional[List[Dict[str, Any]]], pinecone_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ë‘ ê²°ê³¼ë¥¼ merge â†’ ê°•ì˜ ì •ë³´ + ë¦¬ë·° ì •ë³´ í†µí•©
    
    Args:
        mongo_candidates: MongoDBì—ì„œ ê²€ìƒ‰ëœ ê°•ì˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        pinecone_results: Pineconeì—ì„œ ê²€ìƒ‰ëœ ê°•ì˜í‰ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        Dict: ë³‘í•©ëœ ê°•ì˜ ì •ë³´ (course_nameë³„ë¡œ ê·¸ë£¹í™”, ë¦¬ë·° í¬í•¨)
    """
    # course_nameë³„ë¡œ ê°•ì˜í‰ ê·¸ë£¹í™”
    reviews_by_course = defaultdict(list)
    
    for review in pinecone_results:
        metadata = review.get("metadata", {})
        course_name = metadata.get("course_name", "")
        
        if course_name:
            review_data = {
                "text": review.get("text", ""),
                "review_id": metadata.get("original_id", ""),
                "sentiment": None  # í–¥í›„ ê°ì • ë¶„ì„ ì¶”ê°€ ê°€ëŠ¥
            }
            reviews_by_course[course_name].append(review_data)
    
    # MongoDB ê°•ì˜ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
    if mongo_candidates:
        courses = []
        mongo_course_map = {course.get("course_name", ""): course for course in mongo_candidates if course.get("course_name")}
        
        for course_name, reviews in reviews_by_course.items():
            mongo_course = mongo_course_map.get(course_name, {})
            
            course_entry = {
                "course_name": course_name,
                "professor": mongo_course.get("professor", ""),
                "department": mongo_course.get("department", ""),
                "rating": mongo_course.get("rating", 0.0) or mongo_course.get("average_rating", 0.0),
                "review_count": len(reviews),
                "reviews": reviews
            }
            courses.append(course_entry)
        
        # MongoDBì— ìˆì§€ë§Œ ë¦¬ë·°ê°€ ì—†ëŠ” ê°•ì˜ë„ ì¶”ê°€
        for course in mongo_candidates:
            course_name = course.get("course_name", "")
            if course_name and course_name not in reviews_by_course:
                course_entry = {
                    "course_name": course_name,
                    "professor": course.get("professor", ""),
                    "department": course.get("department", ""),
                    "rating": course.get("rating", 0.0) or course.get("average_rating", 0.0),
                    "review_count": 0,
                    "reviews": []
                }
                courses.append(course_entry)
    else:
        # MongoDB í›„ë³´ê°€ ì—†ëŠ” ê²½ìš° (semantic-only queries)
        # Pinecone metadataì—ì„œë§Œ ê°•ì˜ ì •ë³´ ì¶”ì¶œ
        courses = []
        course_info_map = {}
        
        for review in pinecone_results:
            metadata = review.get("metadata", {})
            course_name = metadata.get("course_name", "")
            
            if course_name and course_name not in course_info_map:
                course_info_map[course_name] = {
                    "professor": metadata.get("professor", ""),
                    "department": metadata.get("department", ""),
                    "rating": metadata.get("rating", 0.0)
                }
        
        for course_name, reviews in reviews_by_course.items():
            info = course_info_map.get(course_name, {})
            course_entry = {
                "course_name": course_name,
                "professor": info.get("professor", ""),
                "department": info.get("department", ""),
                "rating": float(info.get("rating", 0.0)) if info.get("rating") else 0.0,
                "review_count": len(reviews),
                "reviews": reviews
            }
            courses.append(course_entry)
    
    return {
        "courses": courses
    }

def normalize_context(merged_context: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë³‘í•©ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ì—¬ LLM í”„ë¡¬í”„íŠ¸ì— ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì²˜ë¦¬
    
    Args:
        merged_context: merge_results()ì˜ ì¶œë ¥
        
    Returns:
        Dict: ì •ê·œí™”ëœ ì»¨í…ìŠ¤íŠ¸ (ëª¨ë“  í•„ìˆ˜ í•„ë“œ ë³´ì¥, ë¦¬ë·° í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ)
    """
    normalized = {
        "courses": []
    }
    
    for course in merged_context.get("courses", []):
        # í•„ìˆ˜ í•„ë“œ ë³´ì¥
        normalized_course = {
            "course_name": course.get("course_name", ""),
            "professor": course.get("professor", ""),
            "department": course.get("department", ""),
            "rating": float(course.get("rating", 0.0)),
            "review_count": int(course.get("review_count", 0)),
            "reviews": []
        }
        
        # ë¦¬ë·° ì •ê·œí™” (í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ)
        reviews = course.get("reviews", [])
        for review in reviews:
            review_text = review.get("text", "")
            # ë¦¬ë·° í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì²« 200ìë§Œ ì‚¬ìš©
            if len(review_text) > 200:
                review_text = review_text[:200] + "..."
            
            normalized_review = {
                "text": review_text,
                "review_id": review.get("review_id", ""),
                "sentiment": review.get("sentiment")
            }
            normalized_course["reviews"].append(normalized_review)
        
        # review_countë¥¼ ì‹¤ì œ ë¦¬ë·° ê°œìˆ˜ë¡œ ì—…ë°ì´íŠ¸
        normalized_course["review_count"] = len(normalized_course["reviews"])
        
        normalized["courses"].append(normalized_course)
    
    return normalized

def synthesize_answer_with_llm(user_query: str, merged_context: Dict[str, Any], conversation_history: list = None) -> str:
    """
    LLM ìµœì¢… ì‘ë‹µ ìƒì„± (Gemini)
    
    Args:
        user_query: ì‚¬ìš©ì ì§ˆë¬¸
        merged_context: merge_results()ì˜ ì¶œë ¥
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì )
        
    Returns:
        str: Geminiê°€ ìƒì„±í•œ ìµœì¢… ë‹µë³€
    """
    try:
        # ì»¨í…ìŠ¤íŠ¸ ì •ê·œí™”
        normalized_context = normalize_context(merged_context)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ ìƒì„± (ìµœê·¼ 5ê°œë§Œ)
        history_text = ""
        if conversation_history:
            history_items = []
            for hist in conversation_history[-5:]:
                user_msg = hist.get("user", "").strip()
                assistant_msg = hist.get("assistant", "").strip()
                if user_msg and assistant_msg:
                    history_items.append(f"ì‚¬ìš©ì: {user_msg}\nì–´ì‹œìŠ¤í„´íŠ¸: {assistant_msg}")
            if history_items:
                history_text = "\n\nì´ì „ ëŒ€í™”(ìˆìœ¼ë©´):\n" + "\n\n".join(history_items) + "\n"
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""{history_text}ì‚¬ìš©ì ì§ˆë¬¸:
{user_query}

ì•„ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ê°•ì˜ ì •ë³´ ë° ê°•ì˜í‰ ë¦¬ë·° ë°ì´í„°ì…ë‹ˆë‹¤.
ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1) ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ì— ë§ëŠ” ì¶”ì²œ ë˜ëŠ” ì¡°ì–¸ ì œì‹œê°€ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤.
2) í•„ìš”í•œ ê²½ìš° ê°•ì˜ íŠ¹ì§• ìš”ì•½ ë˜ëŠ” êµìˆ˜ë‹˜ì˜ ê°•ì˜ ìŠ¤íƒ€ì¼/íŠ¹ì§• ìš”ì•½
4) í•„ìš”í•œ ê²½ìš° ê°•ì˜í‰ì„ ê¸°ë°˜ìœ¼ë¡œ ì¥ì /ë‹¨ì  ì •ë¦¬
5) ì—¬ëŸ¬ ê°•ì˜ê°€ ìˆì„ ê²½ìš° ì •í™•ë„ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìµœëŒ€ 3ê°œê¹Œì§€ ë¹„êµ í›„ ì•ˆë‚´
6) ì •ë³´ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì ˆëŒ€ ê±°ì§“ ìƒì„±í•˜ì§€ ë§ê³ , ì‚¬ì‹¤ëŒ€ë¡œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  ë§í•  ê²ƒ
7) JSONì´ ì•„ë‹ˆë¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€ ìƒì„±
8) ê°•ì˜í‰ì— ê³¼ë„í•˜ê²Œ ë¹„ë‚œì ì¸ ë‚´ìš©ì´ë‚˜ ë¶€ì •ì ì¸ ë‚´ìš©ì€ ë°°ì œí•˜ê±°ë‚˜ ìˆœí™”í•´ì„œ ë§í•  ê²ƒ
9) í•„ìš”ì‹œ ê°„ë‹¨í•œ í¬ë§·íŒ…ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
   - ê°•ì¡°ê°€ í•„ìš”í•œ ë¶€ë¶„ì€ **êµµê²Œ** í‘œì‹œ
   - ê¸°ìš¸ì„ì´ í•„ìš”í•œ ë¶€ë¶„ì€ *ê¸°ìš¸ì„* í‘œì‹œ
   - ì—¬ëŸ¬ í•­ëª© ë‚˜ì—´ ì‹œ ì¤„ë°”ê¿ˆ í™œìš©
   - ë‹¨, ê³¼ë„í•œ í¬ë§·íŒ…ì€ í”¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìœ ì§€í•˜ì„¸ìš”

ê°•ì˜ ë°ì´í„°(JSON):
{json.dumps(normalized_context, ensure_ascii=False, indent=2)}"""

        # Gemini ëª¨ë¸ í˜¸ì¶œ
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        
        # ì‘ë‹µ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ (ai_api.pyì˜ generate_gemini_responseì™€ ë™ì¼í•œ ë°©ì‹)
        # getattrë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼í•˜ê³ , ì‹¤íŒ¨ ì‹œ str(response)ë¡œ fallback
        response_text = getattr(response, 'text', None) or str(response)
        
        # ë¹ˆ ì‘ë‹µì´ê±°ë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ì¸ ê²½ìš° ì²˜ë¦¬
        if not response_text or len(response_text.strip()) == 0:
            # candidatesì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
            if response.candidates and len(response.candidates) > 0:
                candidate = response.candidates[0]
                finish_reason = getattr(candidate, 'finish_reason', None)
                
                # finish_reason í™•ì¸ (1=STOP ì •ìƒ, 2=MAX_TOKENS, 3=SAFETY, 4=RECITATION)
                if finish_reason == 3:  # SAFETY - ì•ˆì „ í•„í„°ì— ê±¸ë¦¼
                    return "ì£„ì†¡í•©ë‹ˆë‹¤. ì•ˆì „ í•„í„°ë¡œ ì¸í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ì£¼ì„¸ìš”."
                elif finish_reason == 2:  # MAX_TOKENS - í† í° ì œí•œ
                    return "ë‹µë³€ì´ ë„ˆë¬´ ê¸¸ì–´ì„œ ì¼ë¶€ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤."
                elif finish_reason == 4:  # RECITATION - ì¸ìš© ë¬¸ì œ
                    return "ì¸ìš© ë¬¸ì œë¡œ ì¸í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                # partsì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if hasattr(candidate, 'content') and candidate.content:
                    if hasattr(candidate.content, 'parts') and candidate.content.parts:
                        parts_text = []
                        for part in candidate.content.parts:
                            if hasattr(part, 'text') and part.text:
                                parts_text.append(part.text)
                        if parts_text:
                            return '\n'.join(parts_text)
            
            return "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        return response_text
        
    except Exception as e:
        print(f"âŒ LLM ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RAG Chat API ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 
# ìš”ì²­ ì˜ˆì‹œ:
# POST /api/v2/rag/chat
# Content-Type: application/json
# {
#   "query": "ë°ì´í„°ë² ì´ìŠ¤ ê°•ì˜ ì¶”ì²œí•´ì¤˜",
#   "history": [
#     {
#       "user": "ì•Œê³ ë¦¬ì¦˜ ê°•ì˜ ì¶”ì²œí•´ì¤˜",
#       "assistant": "ì•Œê³ ë¦¬ì¦˜ ê°•ì˜ë¡œëŠ”..."
#     }
#   ]
# }
#
# ì‘ë‹µ ì˜ˆì‹œ (ì„±ê³µ):
# {
#   "answer": "ë‹µë³€ ìƒì„± ì¤‘...",
#   "debug": {
#     "intent": {
#       "needs_structured_filter": false,
#       "filters": {},
#       "semantic_query": "ë°ì´í„°ë² ì´ìŠ¤ ê°•ì˜ ì¶”ì²œí•´ì¤˜"
#     },
#     "mongo_candidates": 0,
#     "pinecone_hits": 0
#   }
# }
@app.route("/api/v2/rag/chat", methods=["POST"])
def rag_chat():
    """RAG ê¸°ë°˜ ì±—ë´‡ API"""
    try:
        body = request.get_json()
        user_query = body.get("query", "").strip()
        conversation_history = body.get("history", [])  # ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì )
        
        if not user_query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # Step 1: ì§ˆë¬¸ ë¶„ì„ (Structured / Semantic ë¶„ë¦¬)
        intent = classify_query_intent(user_query)
        
        # Step 2: êµ¬ì¡°ì  í•„í„° í•„ìš” ì—¬ë¶€ í™•ì¸
        if intent.needs_structured_filter:
            mongo_candidates = filter_from_mongodb(intent.filters)
        else:
            mongo_candidates = None
        
        # Step 3: Pinecone ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (ë¹„êµ ëŒ€ìƒ ë³´ì¥)
        comparison_targets = intent.comparison_targets
        pinecone_results = semantic_search_pinecone(
            query=intent.semantic_query,
            candidates=mongo_candidates,
            comparison_targets=comparison_targets
        )
        
        # Step 4: ë‘ ê²°ê³¼ë¥¼ merge â†’ ê°•ì˜ ì •ë³´ + ë¦¬ë·° ì •ë³´ í†µí•©
        merged_context = merge_results(
            mongo_candidates,
            pinecone_results
        )
        
        # Step 5: Pinecone ê²°ê³¼ë¥¼ top_reviews í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        top_reviews = []
        for result in pinecone_results[:5]:  # ìƒìœ„ 5ê°œë§Œ
            metadata = result.get("metadata", {})
            review_text = result.get("text", "")  # ê°•ì˜í‰ í…ìŠ¤íŠ¸
            review_rating = metadata.get("rating", None)
            
            # ratingì´ ìˆ«ìë©´ floatë¡œ ë³€í™˜, ì•„ë‹ˆë©´ None
            if review_rating is not None:
                try:
                    review_rating = float(review_rating)
                except (ValueError, TypeError):
                    review_rating = None
            
            review_item = {
                "course_name": metadata.get("course_name", ""),
                "professor": metadata.get("professor", ""),
                "text": review_text,  # ê°•ì˜í‰ í…ìŠ¤íŠ¸
                "rating": review_rating,  # ê°•ì˜í‰ì˜ rating
            }
            top_reviews.append(review_item)
        
        # Step 6: LLM ìµœì¢… ì‘ë‹µ ìƒì„± (Gemini)
        final_answer = synthesize_answer_with_llm(
            user_query,
            merged_context,
            conversation_history
        )
        
        # Step 7: ì‘ë‹µ ë°˜í™˜
        return jsonify({
            "answer": final_answer,
            "top_reviews": top_reviews,
            "provider": "rag-v2",
            "debug": {
                "intent": intent.model_dump(),  # Pydantic BaseModelì„ dictë¡œ ë³€í™˜
                "mongo_candidates": len(mongo_candidates) if mongo_candidates else 0,
                "pinecone_hits": len(pinecone_results)
            }
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/api/v2/rag/test/intent", methods=["POST"])
def test_classify_intent():
    """
    ì§ˆë¬¸ ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/intent
    Content-Type: application/json
    {
      "query": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜"
    }
    
    ì‘ë‹µ ì˜ˆì‹œ:
    {
      "query": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜",
      "intent": {
        "needs_structured_filter": true,
        "filters": {
          "department": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼",
          "course_type": "ì „í•„"
        },
        "semantic_query": "ê³¼ëª© ì¶”ì²œí•´ì¤˜"
      }
    }
    """
    try:
        body = request.get_json() or {}
        user_query = body.get("query", "").strip()
        
        if not user_query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # ì§ˆë¬¸ ì˜ë„ ë¶„ì„
        intent = classify_query_intent(user_query)
        
        return jsonify({
            "query": user_query,
            "intent": intent.model_dump()
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/v2/rag/test/intent/batch", methods=["POST"])
def test_classify_intent_batch():
    """
    ì—¬ëŸ¬ ì§ˆë¬¸ì„ í•œë²ˆì— í…ŒìŠ¤íŠ¸í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/intent/batch
    Content-Type: application/json
    {
      "queries": [
        "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜",
        "ì´ë²ˆ í•™ê¸°ì— ì—´ë¦¬ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê°•ì˜ ì¶”ì²œí•´ì¤˜",
        "ì†ê²½ì•„ êµìˆ˜ë‹˜ ì–´ë•Œ?",
        "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜ ì¶”ì²œí•´ì¤˜"
      ]
    }
    """
    try:
        body = request.get_json() or {}
        queries = body.get("queries", [])
        
        if not queries or not isinstance(queries, list):
            return jsonify({"error": "queries íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (ë°°ì—´)"}), 400
        
        results = []
        for query in queries:
            try:
                intent = classify_query_intent(query)
                results.append({
                    "query": query,
                    "intent": intent.model_dump(),
                    "success": True
                })
            except Exception as e:
                results.append({
                    "query": query,
                    "error": str(e),
                    "success": False
                })
        
        return jsonify({
            "total": len(queries),
            "results": results
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/v2/rag/test/mongodb", methods=["POST"])
def test_mongodb_filter():
    """
    MongoDB í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ (ì§ˆë¬¸ìœ¼ë¡œ ìë™ ë¶„ì„)
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/mongodb
    Content-Type: application/json
    {
      "query": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜"
    }
    """
    try:
        body = request.get_json() or {}
        user_query = body.get("query", "").strip()
        
        if not user_query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # Intent ë¶„ì„ í›„ filters ì¶”ì¶œ
        intent = classify_query_intent(user_query)
        filters = intent.filters
        
        # êµ¬ì¡°ì  í•„í„°ê°€ ë¶ˆí•„ìš”í•œ ê²½ìš°
        if not intent.needs_structured_filter or not filters:
            return jsonify({
                "query": user_query,
                "intent": intent.model_dump(),
                "message": "êµ¬ì¡°ì  í•„í„°ê°€ ë¶ˆí•„ìš”í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤. MongoDB í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.",
                "filters": {},
                "count": 0,
                "results": []
            })
        
        # MongoDB í•„í„°ë§ ì‹¤í–‰
        results = filter_from_mongodb(filters)
        
        return jsonify({
            "query": user_query,
            "intent": intent.model_dump(),
            "filters": filters,
            "count": len(results) if results else 0,
            "results": results or []
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/v2/rag/test/pinecone", methods=["POST"])
def test_pinecone_search():
    """
    Pinecone ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/pinecone
    Content-Type: application/json
    {
      "query": "ê³¼ì œ ë³„ë¡œ ì—†ëŠ” ê°•ì˜",
      "candidates": [
        {"course_name": "ë°ì´í„°ë² ì´ìŠ¤"},
        {"course_name": "ìë£Œêµ¬ì¡°"}
      ],
      "top_k": 5
    }
    """
    try:
        body = request.get_json() or {}
        query = body.get("query", "").strip()
        candidates = body.get("candidates", None)
        top_k = body.get("top_k", 5)
        
        if not query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # Pinecone ê²€ìƒ‰ ì‹¤í–‰
        results = semantic_search_pinecone(query, candidates, top_k)
        
        return jsonify({
            "query": query,
            "candidates_count": len(candidates) if candidates else 0,
            "top_k": top_k,
            "results_count": len(results),
            "results": results
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/v2/rag/test/full", methods=["POST"])
def test_full_rag_pipeline():
    """
    ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ (ë‹µë³€ ìƒì„± ì œì™¸)
    
    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/rag/test/full
    Content-Type: application/json
    {
      "query": "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ê³µ í•„ìˆ˜(ì „í•„) ê³¼ëª© ì¶”ì²œí•´ì¤˜"
    }
    """
    try:
        body = request.get_json() or {}
        user_query = body.get("query", "").strip()
        
        if not user_query:
            return jsonify({"error": "query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # Step 1: ì§ˆë¬¸ ë¶„ì„
        intent = classify_query_intent(user_query)
        
        # Step 2: MongoDB í•„í„°ë§
        mongo_candidates = None
        if intent.needs_structured_filter:
            mongo_candidates = filter_from_mongodb(intent.filters)
        
        # Step 3: Pinecone ê²€ìƒ‰
        pinecone_results = semantic_search_pinecone(
            query=intent.semantic_query,
            candidates=mongo_candidates
        )
        
        # Step 4: ê²°ê³¼ ë³‘í•©
        merged_context = merge_results(mongo_candidates, pinecone_results)
        
        return jsonify({
            "query": user_query,
            "intent": intent.model_dump(),
            "mongo_candidates": {
                "count": len(mongo_candidates) if mongo_candidates else 0,
                "courses": mongo_candidates[:5] if mongo_candidates else []  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            },
            "pinecone_results": {
                "count": len(pinecone_results),
                "reviews": pinecone_results[:5]  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            },
            "merged_context": merged_context
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5005, debug=True)